{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix factorization under Pytorch\n",
    "I follow the [tutorial](http://blog.ethanrosenthal.com/2017/06/20/matrix-factorization-in-pytorch/) to code matrix factorization under PyTorch 0.4.0 and Python 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import rand as sprand\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "n_users = 1000\n",
    "n_items = 1000\n",
    "ratings = sprand(n_users, n_items, \n",
    "                 density=0.01, format='csr')\n",
    "ratings.data = (np.random.randint(1, 5, \n",
    "                                  size=ratings.nnz)\n",
    "                          .astype(np.float64))\n",
    "ratings = ratings.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorization(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, n_users, n_items, n_factors=20):\n",
    "        super().__init__()\n",
    "        self.user_factors = torch.nn.Embedding(n_users, \n",
    "                                               n_factors,\n",
    "                                               sparse=True)\n",
    "        self.item_factors = torch.nn.Embedding(n_items, \n",
    "                                               n_factors,\n",
    "                                               sparse=True)\n",
    "        \n",
    "    def forward(self, user, item):\n",
    "        return (self.user_factors(user) * self.item_factors(item)).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MatrixFactorization(n_users, n_items, n_factors=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "loss_func = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimization technique\n",
    "optimizer = torch.optim.SGD(model.parameters(), \n",
    "                            lr=1e-6) # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort our data\n",
    "rows, cols = ratings.nonzero()\n",
    "p = np.random.permutation(len(rows))\n",
    "rows, cols = rows[p], cols[p]\n",
    "\n",
    "for row, col in zip(*(rows, cols)):\n",
    "    # Turn data into variables\n",
    "    rating = Variable(torch.FloatTensor([ratings[row, col]]))\n",
    "    row = Variable(torch.LongTensor([np.long(row)]))\n",
    "    col = Variable(torch.LongTensor([np.long(col)]))\n",
    "    \n",
    "    # Predict and calculate loss\n",
    "    prediction = model(row, col)\n",
    "    loss = loss_func(prediction, rating)\n",
    "    \n",
    "    # Backpropagate\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update the parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.6602,  0.2753,  0.7919,  ..., -0.6638, -0.4608, -1.0459],\n",
      "        [ 0.1122,  0.9136,  1.4134,  ...,  0.2170,  0.4223, -1.6526],\n",
      "        [-1.0616,  0.9610,  0.6030,  ..., -1.5356,  0.8040,  0.0736],\n",
      "        ...,\n",
      "        [ 0.3877, -0.6013, -0.0516,  ..., -0.3256,  0.0125, -0.9368],\n",
      "        [ 0.3810, -2.1886,  1.0221,  ...,  0.2800,  0.6728,  0.8364],\n",
      "        [-0.0005,  0.5182,  1.0412,  ..., -0.9755,  0.3677,  1.6703]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# print user latent factor\n",
    "print(model.user_factors.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.1698, -1.7126,  0.4861,  ...,  0.4945,  0.8796,  0.7173],\n",
      "        [ 1.0134,  1.7968,  0.4016,  ..., -0.5096,  1.0018, -0.1825],\n",
      "        [ 1.2538, -0.1432,  0.0577,  ..., -0.2004, -1.2428, -0.2907],\n",
      "        ...,\n",
      "        [-1.0364,  0.8970,  0.6789,  ..., -0.3816,  1.0716, -0.3105],\n",
      "        [-0.5187, -0.2775,  0.9966,  ..., -1.4349, -1.0049,  0.0762],\n",
      "        [ 0.8415, -2.3906, -0.2427,  ...,  1.8611,  0.6607, -0.4663]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# print venue latent factor\n",
    "print(model.item_factors.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
